{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "collapsed_sections": [
        "3G_WcoY16jk1",
        "jADAx3RPuVCU",
        "TYFOlUb2ub5L",
        "baSqKgTXWRRY",
        "n-aefwDRwn92",
        "9QiEldJ3zeko",
        "YbawgKQm0jYb",
        "xNbKzRVV6EFn"
      ],
      "authorship_tag": "ABX9TyPQHQVOIw3tNqrq43avJvui",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinhajiya/NLP/blob/main/N-Gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the libraries"
      ],
      "metadata": {
        "id": "3G_WcoY16jk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from collections import Counter\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n"
      ],
      "metadata": {
        "id": "mhiE7ZkNuvmD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "uBEXeSZsuepk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning GitHub repo for dataset"
      ],
      "metadata": {
        "id": "jADAx3RPuVCU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-EISdf_t_FO",
        "outputId": "bf50ab94-e72f-4ac1-e9d1-05a37e103210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Assignment_1_2025' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/islnlp/Assignment_1_2025"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data and preprocessing"
      ],
      "metadata": {
        "id": "TYFOlUb2ub5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(name):\n",
        "  root_fp = f\"/content/Assignment_1_2025/{name}\"\n",
        "  train = pd.read_csv(os.path.join(root_fp, \"train.csv\"))\n",
        "  val = pd.read_csv(os.path.join(root_fp, \"val.csv\"))\n",
        "  train = train.dropna(subset=['Sentence'])\n",
        "  val = val.dropna(subset=['Sentence'])\n",
        "  return train, val"
      ],
      "metadata": {
        "id": "c816MxzhvWEN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(Sentence):\n",
        "\n",
        "  # Preprocessing steps:\n",
        "  # 1. All lower case characters\n",
        "  # 2. URL removal\n",
        "  # 3. Multiple dots to single dot\n",
        "  # 4. Extra spaces to single space\n",
        "  # 5. Removes non-alphabetic chars\n",
        "\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    Sentence = Sentence.lower()\n",
        "    Sentence = re.sub(url_pattern, \"\", Sentence)\n",
        "    Sentence = re.sub(r\"\\.{2,}\", \".\", Sentence)\n",
        "    Sentence = re.sub(r\"\\s+\", \" \", Sentence).strip()\n",
        "    Sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", Sentence)\n",
        "    return Sentence"
      ],
      "metadata": {
        "id": "ABazvC3PTjDs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(name):\n",
        "\n",
        "  train, val = load_data(name)\n",
        "  print(f\"Loading and preprocessing the {name} data... \\n\")\n",
        "  print(f\"Train shape: {train.shape}, Val shape: {val.shape}\\n\")\n",
        "  print(f\"The dataset before preprocessing...\\n\")\n",
        "  print(f\"Train head: \\n {train.head()}\\n\")\n",
        "  print(f\"Val head: \\n {val.head()}\\n\")\n",
        "  print(f\"Class distribution of training data: {Counter(train['Tag'])}\")\n",
        "  train[\"Sentence_preprocessed\"] = train[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "  val[\"Sentence_preprocessed\"] = val[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "  print(f\"The dataset after preprocessing...\\n\")\n",
        "  print(f\"Train head: \\n {train.head()}\\n\")\n",
        "  print(f\"Val head: \\n {val.head()}\\n\")\n",
        "\n",
        "  return train, val"
      ],
      "metadata": {
        "id": "Gx-AJd9kUMO0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction"
      ],
      "metadata": {
        "id": "baSqKgTXWRRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using N-gram language models (unigrams, bigrams, trigrams)\n",
        "as features."
      ],
      "metadata": {
        "id": "TkT3ldNxWaNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(train, val):\n",
        "  vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
        "  train_features = vectorizer.fit_transform(train['Sentence_preprocessed'])\n",
        "  y_train = train['Tag']\n",
        "  val_features = vectorizer.transform(val['Sentence_preprocessed'])\n",
        "  y_val = val['Tag']\n",
        "  print(f\"The shape of training data: {train_features.shape}\\n\")\n",
        "  print(f\"The shape of validation data: {val_features.shape}\\n\")\n",
        "\n",
        "  vocab = vectorizer.get_feature_names_out()\n",
        "  random_sample = np.random.choice(vocab, 20, replace=False)\n",
        "  print(f\"Printing a sample of the vocabulary: \\n{random_sample}\\n\")\n",
        "\n",
        "  unigrams = [word for word in vocab if len(word.split()) == 1]\n",
        "  bigrams = [word for word in vocab if len(word.split()) == 2]\n",
        "  trigrams = [word for word in vocab if len(word.split()) == 3]\n",
        "\n",
        "  print(f\"\\n Unigrams: {len(unigrams)}, Bigrams: {len(bigrams)}, Trigrams: {len(trigrams)}\\n\")\n",
        "  print(f\"Sample Unigrams: {unigrams[:5]} \\n\")\n",
        "  print(f\"Sample Bigrams: {bigrams[:5]} \\n\")\n",
        "  print(f\"Sample Trigrams: {trigrams[:5]} \\n\")\n",
        "  print(f\"The total count of the grams (features) generated: {len(unigrams) + len(bigrams) + len(trigrams)}\")\n",
        "\n",
        "  return train_features, val_features, y_train,  y_val"
      ],
      "metadata": {
        "id": "GQPdN67b6QMn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "n-aefwDRwn92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(X, y, isclassbalanced = False):\n",
        "\n",
        "  if not isclassbalanced:\n",
        "    print(f\"Class distribution before resampling: {Counter(y)}\")\n",
        "    undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "    X_train, y_train = undersampler.fit_resample(X, y)\n",
        "    print(f\"Class distribution after resampling: {Counter(y_train)}\")\n",
        "\n",
        "  else:\n",
        "    X_train, y_train = X, y\n",
        "  nb_model = MultinomialNB()\n",
        "  param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0]}\n",
        "  grid_search = GridSearchCV(nb_model, param_grid, cv=5, scoring='f1_macro', verbose=2, n_jobs=-1)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "  print(f\"Best Parameters for the Naive Bayes model is {grid_search.best_params_}\")\n",
        "  best_nb = grid_search.best_estimator_\n",
        "  return best_nb"
      ],
      "metadata": {
        "id": "blfM6krDxMlX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, X_val, y_val):\n",
        "  y_pred = model.predict(X_val)\n",
        "  print(f\"Validation Accuracy: {accuracy_score(y_val, y_pred)} \\n\")\n",
        "  print(f\"Classification Report:\\n {classification_report(y_val, y_pred)}\")"
      ],
      "metadata": {
        "id": "6ySZCptByrII"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hate Dataset"
      ],
      "metadata": {
        "id": "9QiEldJ3zeko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = load_and_preprocess_data('hate')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR8vkMmo0P7-",
        "outputId": "7868e98d-0413-40bd-ed2f-b7513e6bfa46"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing the hate data... \n",
            "\n",
            "Train shape: (3660, 2), Val shape: (457, 2)\n",
            "\n",
            "The dataset before preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag\n",
            "0  #hariyana mey ek week mey teen bachchiyo ke Sa...    1\n",
            "1  indira Gandhi ko marne wala sikh.Rajiv Gandhi ...    1\n",
            "2  ishliye corruption ke jariye sab ki khoon choo...    1\n",
            "3  Pakistaniyon ko aisi news Maamul sa ho Gaya ha...    0\n",
            "4  Apne national anthem ko change karo and yeh li...    1\n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag\n",
            "0          Sahee bolay ho kal Pakistani ka rape hoga    0\n",
            "1                    rape. Pyaar rape se kum nhi hai    0\n",
            "2  ye log mandir me hi q jakar rape krte kaya bi ...    0\n",
            "3  Delhi-Dehradun train mein 1seat par baithne k ...    0\n",
            "4  #GadhaAkallesh ne Kairana/Sahibabad/Buxar se H...    1\n",
            "\n",
            "Class distribution of training data: Counter({0: 2307, 1: 1353})\n",
            "The dataset after preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag  \\\n",
            "0  #hariyana mey ek week mey teen bachchiyo ke Sa...    1   \n",
            "1  indira Gandhi ko marne wala sikh.Rajiv Gandhi ...    1   \n",
            "2  ishliye corruption ke jariye sab ki khoon choo...    1   \n",
            "3  Pakistaniyon ko aisi news Maamul sa ho Gaya ha...    0   \n",
            "4  Apne national anthem ko change karo and yeh li...    1   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0  hariyana mey ek week mey teen bachchiyo ke saa...  \n",
            "1  indira gandhi ko marne wala sikhrajiv gandhi k...  \n",
            "2  ishliye corruption ke jariye sab ki khoon choo...  \n",
            "3  pakistaniyon ko aisi news maamul sa ho gaya ha...  \n",
            "4  apne national anthem ko change karo and yeh li...  \n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag  \\\n",
            "0          Sahee bolay ho kal Pakistani ka rape hoga    0   \n",
            "1                    rape. Pyaar rape se kum nhi hai    0   \n",
            "2  ye log mandir me hi q jakar rape krte kaya bi ...    0   \n",
            "3  Delhi-Dehradun train mein 1seat par baithne k ...    0   \n",
            "4  #GadhaAkallesh ne Kairana/Sahibabad/Buxar se H...    1   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0          sahee bolay ho kal pakistani ka rape hoga  \n",
            "1                     rape pyaar rape se kum nhi hai  \n",
            "2  ye log mandir me hi q jakar rape krte kaya bi ...  \n",
            "3  delhidehradun train mein seat par baithne k li...  \n",
            "4  gadhaakallesh ne kairanasahibabadbuxar se hind...  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = extract_features(train, val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNxlCxA155NV",
        "outputId": "d6b285a6-24ed-4fb6-e16e-b30b031c9e89"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data: (3660, 120493)\n",
            "\n",
            "The shape of validation data: (457, 120493)\n",
            "\n",
            "Printing a sample of the vocabulary: \n",
            "['pr mery' 'diya chosne ko' 'chutiyaape faila' 'dahej' 'fawad teri baji'\n",
            " 'emaan ap' 'to rape bina' 'ga hamare chief' 'polity ka' 'andhe bhakt'\n",
            " 'pe kiya' 'ki daring ct' 'jaane waali baat' 'sena tab kidhar' 'bachayi'\n",
            " 'hai toh khud' 'she was' 'gupta ko bura' 'palo ma mehsoos'\n",
            " 'vikas hate nai']\n",
            "\n",
            "\n",
            " Unigrams: 12910, Bigrams: 48170, Trigrams: 59413\n",
            "\n",
            "Sample Unigrams: ['aa', 'aaa', 'aaaj', 'aaaleee', 'aaap'] \n",
            "\n",
            "Sample Bigrams: ['aa gae', 'aa gai', 'aa gaya', 'aa gaye', 'aa gayi'] \n",
            "\n",
            "Sample Trigrams: ['aa gae hai', 'aa gai ghar', 'aa gaya bharat', 'aa gaye bakwas', 'aa gaye hain'] \n",
            "\n",
            "The total count of the grams (features) generated: 120493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqEDnEZg65Uc",
        "outputId": "e7bcd9da-5e81-4068-8559-8c5f8d6c4e11"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 1353, 0: 2307})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1353/2307"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA3QFi-w7uoC",
        "outputId": "27da105e-78dd-4a35-8cd6-6c40a4461f39"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5864759427828349"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is a class imbalance, use isclassbalanced = False:"
      ],
      "metadata": {
        "id": "BsIFGKqy7Fzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(X_train, y_train, isclassbalanced=False)\n",
        "test_model(model, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI0aSsin5xWq",
        "outputId": "ad9ce3ba-6878-48e9-fd43-ca34d3fb881d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before resampling: Counter({0: 2307, 1: 1353})\n",
            "Class distribution after resampling: Counter({0: 1353, 1: 1353})\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Best Parameters for the Naive Bayes model is {'alpha': 1.0}\n",
            "Validation Accuracy: 0.5776805251641138 \n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.50      0.62       309\n",
            "           1       0.41      0.73      0.53       148\n",
            "\n",
            "    accuracy                           0.58       457\n",
            "   macro avg       0.60      0.62      0.57       457\n",
            "weighted avg       0.67      0.58      0.59       457\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Humor"
      ],
      "metadata": {
        "id": "YbawgKQm0jYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = load_and_preprocess_data('humor')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24d_JVgJ0kb6",
        "outputId": "7496a357-0bcd-4c19-f637-dd7c644a9fa6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing the humor data... \n",
            "\n",
            "Train shape: (2360, 2), Val shape: (295, 2)\n",
            "\n",
            "The dataset before preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag\n",
            "0  Jyotiraditya Scindia is like \"Rassi jal gayee ...    1\n",
            "1                Ishant Sharma ko bahut late utaara.    1\n",
            "2           .@twinitisha neeche plug nikla hua hai..    0\n",
            "3  Aaj agar India final me hota to kam se kam New...    0\n",
            "4  3 stages of life of Mechanical Engineer:\\n\\n1)...    1\n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag\n",
            "0  .@OfficeOfRG #HappyBdayPM wala hashtag use kar...    0\n",
            "1  \"Main kuch bhi dekh sakta hun bas teri ankhon ...    1\n",
            "2  No rainbow pic cause waise bhi rangeeley kism ...    0\n",
            "3  Hamein aur jeene ki khwahish na hoti, agar rum...    1\n",
            "4  Ladkiyo ke parts pe comment karke gaali khaane...    1\n",
            "\n",
            "Class distribution of training data: Counter({1: 1407, 0: 953})\n",
            "The dataset after preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag  \\\n",
            "0  Jyotiraditya Scindia is like \"Rassi jal gayee ...    1   \n",
            "1                Ishant Sharma ko bahut late utaara.    1   \n",
            "2           .@twinitisha neeche plug nikla hua hai..    0   \n",
            "3  Aaj agar India final me hota to kam se kam New...    0   \n",
            "4  3 stages of life of Mechanical Engineer:\\n\\n1)...    1   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0  jyotiraditya scindia is like rassi jal gayee a...  \n",
            "1                 ishant sharma ko bahut late utaara  \n",
            "2               twinitisha neeche plug nikla hua hai  \n",
            "3  aaj agar india final me hota to kam se kam new...  \n",
            "4   stages of life of mechanical engineer  janam ...  \n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag  \\\n",
            "0  .@OfficeOfRG #HappyBdayPM wala hashtag use kar...    0   \n",
            "1  \"Main kuch bhi dekh sakta hun bas teri ankhon ...    1   \n",
            "2  No rainbow pic cause waise bhi rangeeley kism ...    0   \n",
            "3  Hamein aur jeene ki khwahish na hoti, agar rum...    1   \n",
            "4  Ladkiyo ke parts pe comment karke gaali khaane...    1   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0  officeofrg happybdaypm wala hashtag use karta ...  \n",
            "1  main kuch bhi dekh sakta hun bas teri ankhon m...  \n",
            "2  no rainbow pic cause waise bhi rangeeley kism ...  \n",
            "3  hamein aur jeene ki khwahish na hoti agar rum ...  \n",
            "4  ladkiyo ke parts pe comment karke gaali khaane...  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = extract_features(train, val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4a2SyFq0s_r",
        "outputId": "2a0817cf-f8dc-419a-beb6-ae6cc33ebf9f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data: (2360, 54826)\n",
            "\n",
            "The shape of validation data: (295, 54826)\n",
            "\n",
            "Printing a sample of the vocabulary: \n",
            "['tag kar' 'kaam kar rahe' 'to kabhi cooker' 'aadhar kar do' 'ho jati'\n",
            " 'se iss' 'par sense' 'khade hota' 'dono saath main' 'kaun sa'\n",
            " 'wahi chale aate' 'walo chahe jitna' 'gaand lagi hai' 'ki tareef'\n",
            " 'viagra kaun' 'sabha ki' 'par boner kaayam' 'bacha' 'na kare' 'kuch nami']\n",
            "\n",
            "\n",
            " Unigrams: 7160, Bigrams: 22652, Trigrams: 25014\n",
            "\n",
            "Sample Unigrams: ['aa', 'aaaaaj', 'aaaeee', 'aabaad', 'aabadi'] \n",
            "\n",
            "Sample Bigrams: ['aa aa', 'aa aap', 'aa aayegi', 'aa baithenge', 'aa bhi'] \n",
            "\n",
            "Sample Trigrams: ['aa aa aa', 'aa aa haath', 'aa aap aapt', 'aa aayegi he', 'aa baithenge batein'] \n",
            "\n",
            "The total count of the grams (features) generated: 54826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKEt-ro47YqZ",
        "outputId": "474eff9e-e4bf-412f-c580-0a0e5a1e4803"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 1407, 0: 953})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "953/1407"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E32lK1IC7qPM",
        "outputId": "ecf1e237-ba0d-4430-abde-4b4efeabd2ad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6773276474769012"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(X_train, y_train, isclassbalanced=False)\n",
        "test_model(model, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XutomdgU4chh",
        "outputId": "659f29c8-6d11-4825-b482-95a6f243c5bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before resampling: Counter({1: 1407, 0: 953})\n",
            "Class distribution after resampling: Counter({0: 953, 1: 953})\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Best Parameters for the Naive Bayes model is {'alpha': 1.0}\n",
            "Validation Accuracy: 0.6440677966101694 \n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.43      0.49       119\n",
            "           1       0.67      0.79      0.73       176\n",
            "\n",
            "    accuracy                           0.64       295\n",
            "   macro avg       0.63      0.61      0.61       295\n",
            "weighted avg       0.63      0.64      0.63       295\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SARCASM"
      ],
      "metadata": {
        "id": "xNbKzRVV6EFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = load_and_preprocess_data('sarcasm')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1vRNSFW5XZq",
        "outputId": "1c19eb6d-3ccb-46c7-f1f9-f5e7b64daaa3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing the sarcasm data... \n",
            "\n",
            "Train shape: (4200, 2), Val shape: (525, 2)\n",
            "\n",
            "The dataset before preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag\n",
            "0  MashaAllah, jo log meri Black display peh chor...    1\n",
            "1  Sanjeev, Suchitra Sen, and Gulzar.  #SanjeevKu...    0\n",
            "2  Politics to harami hai par tu sabse bada haram...    0\n",
            "3  aaj cricket khiladi neelam honge... khair khil...    0\n",
            "4  #PAKvWXI  Hamay cricket fever mai Etna mast Na...    0\n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag\n",
            "0  Aek tarf pakistan ke dushman pakistan ke khila...    0\n",
            "1  Lalu ne bihar ki seva karte hue kitne ghotaale...    0\n",
            "2  Politics me har admi besharam ho jata hai.... ...    0\n",
            "3    Kudakudhinge dhuvasthamee?  #Maldives #Politics    0\n",
            "4  Kya ram-rahim naam ke gunde ke bhakto ko manma...    0\n",
            "\n",
            "Class distribution of training data: Counter({0: 3797, 1: 403})\n",
            "The dataset after preprocessing...\n",
            "\n",
            "Train head: \n",
            "                                             Sentence  Tag  \\\n",
            "0  MashaAllah, jo log meri Black display peh chor...    1   \n",
            "1  Sanjeev, Suchitra Sen, and Gulzar.  #SanjeevKu...    0   \n",
            "2  Politics to harami hai par tu sabse bada haram...    0   \n",
            "3  aaj cricket khiladi neelam honge... khair khil...    0   \n",
            "4  #PAKvWXI  Hamay cricket fever mai Etna mast Na...    0   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0  mashaallah jo log meri black display peh chorh...  \n",
            "1  sanjeev suchitra sen and gulzar sanjeevkumar g...  \n",
            "2  politics to harami hai par tu sabse bada haram...  \n",
            "3  aaj cricket khiladi neelam honge khair khiladi...  \n",
            "4  pakvwxi hamay cricket fever mai etna mast nahi...  \n",
            "\n",
            "Val head: \n",
            "                                             Sentence  Tag  \\\n",
            "0  Aek tarf pakistan ke dushman pakistan ke khila...    0   \n",
            "1  Lalu ne bihar ki seva karte hue kitne ghotaale...    0   \n",
            "2  Politics me har admi besharam ho jata hai.... ...    0   \n",
            "3    Kudakudhinge dhuvasthamee?  #Maldives #Politics    0   \n",
            "4  Kya ram-rahim naam ke gunde ke bhakto ko manma...    0   \n",
            "\n",
            "                               Sentence_preprocessed  \n",
            "0  aek tarf pakistan ke dushman pakistan ke khila...  \n",
            "1  lalu ne bihar ki seva karte hue kitne ghotaale...  \n",
            "2  politics me har admi besharam ho jata hai thuk...  \n",
            "3        kudakudhinge dhuvasthamee maldives politics  \n",
            "4  kya ramrahim naam ke gunde ke bhakto ko manmar...  \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = extract_features(train, val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWIb0oe76IVT",
        "outputId": "e90b9786-a81c-4ff9-a654-2b1b6935c5c5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data: (4200, 131081)\n",
            "\n",
            "The shape of validation data: (525, 131081)\n",
            "\n",
            "Printing a sample of the vocabulary: \n",
            "['politics nanga bhi' 'tu chillati' 'ko desh ka' 'ko pareshaan'\n",
            " 'trailer tomorrowpictwittercomrjsggufr' 'haye kyoon pighalne'\n",
            " 'hai jo aap' 'ban ke baad' 'konse jhande' 'ko mila talaq'\n",
            " 'parterrorist ko support' 'dekh lijiye tripletalaq' 'pehna triple talaq'\n",
            " 'dudh' 'bas vote' 'paas jaana' 'ki puja' 'aata hai pr' 'aur bhi khelna'\n",
            " 'ruk gya is']\n",
            "\n",
            "\n",
            " Unigrams: 14536, Bigrams: 52114, Trigrams: 64431\n",
            "\n",
            "Sample Unigrams: ['aa', 'aaa', 'aaaaaaaaaa', 'aaaaaarceeeeeeebeeeeeee', 'aaaj'] \n",
            "\n",
            "Sample Bigrams: ['aa aisa', 'aa chuke', 'aa gai', 'aa gaya', 'aa gayasalman'] \n",
            "\n",
            "Sample Trigrams: ['aa aisa ho', 'aa chuke hai', 'aa gai excuse', 'aa gai hai', 'aa gaya aaj'] \n",
            "\n",
            "The total count of the grams (features) generated: 131081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(y_train) #Highly imbalanced data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bsDwzX578Vx",
        "outputId": "87ee43e1-6d78-4579-a95b-9bb55b2cd775"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1: 403, 0: 3797})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(X_train, y_train, isclassbalanced=False)\n",
        "test_model(model, X_val, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey9NMZf96NWI",
        "outputId": "c253d2f9-9ddb-4da8-beb6-a2f46974ee84"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before resampling: Counter({0: 3797, 1: 403})\n",
            "Class distribution after resampling: Counter({0: 403, 1: 403})\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "Best Parameters for the Naive Bayes model is {'alpha': 0.5}\n",
            "Validation Accuracy: 0.9352380952380952 \n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       474\n",
            "           1       0.62      0.84      0.72        51\n",
            "\n",
            "    accuracy                           0.94       525\n",
            "   macro avg       0.80      0.89      0.84       525\n",
            "weighted avg       0.95      0.94      0.94       525\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdVMx9QR6Qvb"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}