{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinhajiya/NLP/blob/main/Viterbi_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
        "!wget https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt"
      ],
      "metadata": {
        "id": "9eEbVsy0H99u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3151235-97d9-47b6-da42-1f47fb1fde10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-18 16:35:15--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/train_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375849 (367K) [text/plain]\n",
            "Saving to: ‘train_data.txt.11’\n",
            "\n",
            "\rtrain_data.txt.11     0%[                    ]       0  --.-KB/s               \rtrain_data.txt.11   100%[===================>] 367.04K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-18 16:35:15 (11.8 MB/s) - ‘train_data.txt.11’ saved [375849/375849]\n",
            "\n",
            "--2025-03-18 16:35:15--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77062 (75K) [text/plain]\n",
            "Saving to: ‘test_data.txt.11’\n",
            "\n",
            "test_data.txt.11    100%[===================>]  75.26K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-03-18 16:35:15 (5.47 MB/s) - ‘test_data.txt.11’ saved [77062/77062]\n",
            "\n",
            "--2025-03-18 16:35:15--  https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/refs/heads/main/Viterbi_assignment/noisy_test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 77120 (75K) [text/plain]\n",
            "Saving to: ‘noisy_test_data.txt.11’\n",
            "\n",
            "noisy_test_data.txt 100%[===================>]  75.31K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-03-18 16:35:15 (4.58 MB/s) - ‘noisy_test_data.txt.11’ saved [77120/77120]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            sentence = []\n",
        "            for token in line.strip().split():\n",
        "                word, tag = token.rsplit('/', 1)  # Split word and tag\n",
        "                sentence.append((word, tag))\n",
        "            data.append(sentence)\n",
        "    return data\n",
        "\n",
        "# Load train and test data from files\n",
        "train_data_file = '/content/train_data.txt'  # Path to your training data file\n",
        "test_data_file = '/content/test_data.txt'    # Path to your test data file\n",
        "noisy_test_data_file = '/content/noisy_test_data.txt'  # Path to your noisy test data file\n",
        "\n",
        "train_data = load_data(train_data_file)\n",
        "test_data = load_data(test_data_file)\n",
        "noisy_test_data = load_data(noisy_test_data_file)\n",
        "\n",
        "# Print a sample from the training data\n",
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-7XRbJKM2-j",
        "outputId": "840e0de3-12a4-41ab-ecf9-908a576eb713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('He', 'PRON'), ('let', 'VERB'), ('her', 'PRON'), ('tell', 'VERB'), ('him', 'PRON'), ('all', 'PRT'), ('about', 'ADP'), ('the', 'DET'), ('church', 'NOUN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "6fBG2exLhAh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30d2f8e-d008-4711-c64d-ae048f515484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "egzJoO7WhAf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation\n",
        "An example of evaluation:"
      ],
      "metadata": {
        "id": "23eBoIIph4lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [('Get', 'VERB'), ('copper', 'NOUN'), ('or', 'CONJ'), ('earthenware', 'NOUN'), ('mugs', 'NOUN'), ('that', 'PRON'), ('keep', 'VERB'), ('beer', 'NOUN'), ('chilled', 'VERB'), ('or', 'CONJ'), ('soup', 'NOUN'), ('hot', 'ADJ'), ('.', '.')]\n",
        "predicted_tags = ['DET', 'NOUN', 'CONJ', 'NOUN', 'ADP', 'PRON', 'VERB', 'NOUN', '.', 'CONJ', 'NOUN', 'ADJ', '.']\n",
        "true_tags = ('VERB', 'NOUN', 'CONJ', 'NOUN', 'NOUN', 'PRON', 'VERB', 'NOUN', 'VERB', 'CONJ', 'NOUN', 'ADJ', '.')\n",
        "correct = 0\n",
        "total = 0\n",
        "correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
        "total += len(true_tags)\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f\"Baseline Viterbi Accuracy: {accuracy * 100:.2f}%\")\n",
        "# print(f\"Viterbi with Noise Handling Accuracy: {accuracy * 100:.2f}%\")  # similarly calculate for Noise Handling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWy2eyhCfr4S",
        "outputId": "76e50350-a19f-4507-abce-afba2dd1eb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Viterbi Accuracy: 76.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7nH7DessOTSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cOp6J9cSTppw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HMM SETUP"
      ],
      "metadata": {
        "id": "bv_sMJdXaZBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data(data):\n",
        "  tags = (set() ) # POS tags\n",
        "  vocab = (set())   # Words in corpos\n",
        "\n",
        "  for i in data:\n",
        "    for word, tag in i:\n",
        "        tags.add(tag)\n",
        "        vocab.add(word)\n",
        "  return tags, vocab"
      ],
      "metadata": {
        "id": "ReYjhozK0T6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ELEMENTS OF AN HMM MODEL\n",
        "tags, vocab = extract_data(train_data)\n",
        "tags_index = {tags: i for i, tags in enumerate(tags)}\n",
        "no_tags = len(tags)\n",
        "vocab_index = {vocab: i for i, vocab in enumerate(vocab)}\n",
        "vocab_size = len(vocab)"
      ],
      "metadata": {
        "id": "E9nZ4GqyXJZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hExAzlmo9MnA",
        "outputId": "8462c4a0-97db-43ee-fe17-21682d3f77e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'.',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'ADV',\n",
              " 'CONJ',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NUM',\n",
              " 'PRON',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'X'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize (alpha, no_tags=no_tags, vocab_size=vocab_size):\n",
        "  start = np.full((no_tags), alpha)  # Initial state probabilities\n",
        "  tag_transition = np.full((no_tags, no_tags),alpha) # Tag transition: P(t_i|P_i-1)\n",
        "  emissions =  np.full((no_tags, vocab_size),alpha)  # Word likelihood probability (emission)  P(w_i|t_i)\n",
        "  return start, tag_transition, emissions"
      ],
      "metadata": {
        "id": "NKwOXwDWmU1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def form_count_tables(data,alpha):\n",
        "  start, tag_transition, emissions = initialize(alpha)\n",
        "  for i in data:\n",
        "    prev_tag = None\n",
        "    for word, tag in i:\n",
        "        tag = tags_index[tag]\n",
        "        word_index = vocab_index[word]\n",
        "\n",
        "        emissions[tag][word_index] += 1\n",
        "\n",
        "        if prev_tag is not None:\n",
        "            tag_transition[prev_tag][tag] += 1\n",
        "        else:\n",
        "            start[tag] += 1  # First word in sentence\n",
        "        prev_tag = tag\n",
        "  return start, tag_transition, emissions"
      ],
      "metadata": {
        "id": "eq03dRzoXLJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printtable(table, T=True):\n",
        "    if T:\n",
        "        index, columns = tags_index, tags_index\n",
        "    else:\n",
        "        index, columns = tags_index, vocab_index\n",
        "\n",
        "    return(pd.DataFrame(table, index, columns))"
      ],
      "metadata": {
        "id": "42PLUk1oyZie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prob(table, axis=1):\n",
        "  total_counts = np.sum(table, axis=axis, keepdims=True)\n",
        "  total_counts[total_counts == 0] = 1\n",
        "  return table/total_counts"
      ],
      "metadata": {
        "id": "xGHHrjscqutm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def form_prob_table (start, tag_transition, emissions):\n",
        "  start_probs = prob(start, 0)\n",
        "  transition_prob = prob(tag_transition)\n",
        "  emission_prob = prob(emissions)\n",
        "  return start_probs, transition_prob, emission_prob"
      ],
      "metadata": {
        "id": "Q3EJ22eIzAMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Viterbi Implementation"
      ],
      "metadata": {
        "id": "jXqI8cHva9Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi(sentence, setoftags, start_probs , transition_prob , emission_prob):\n",
        "\n",
        "# Initializing values needed\n",
        "    tags = list(setoftags)\n",
        "    no_tags = len(tags)\n",
        "    no_words = len(sentence)\n",
        "    unknown_prob = 1e-4  # Small probability for unknown words\n",
        "    delta = np.zeros((no_tags, no_words))\n",
        "    shi = np.zeros((no_tags, no_words), dtype=int)\n",
        "\n",
        "\n",
        "# Delta and shi for the first word\n",
        "    word = sentence[0] # First word in the sentence\n",
        "\n",
        "    for i, tag in enumerate(tags):\n",
        "        tag_index = tags_index[tag]\n",
        "        if word in vocab_index:\n",
        "            delta[tag_index, 0] = start_probs[tag_index] * emission_prob[tag_index][vocab_index[word]]\n",
        "        else:\n",
        "            delta[tag_index, 0] = start_probs[tag_index] * unknown_prob\n",
        "        shi[tag_index, 0] = 0  # No previous state in the first column\n",
        "\n",
        "# Delta and Shi for the rest of the sentence:\n",
        "    for i in range(1, no_words):  # For a word in the sentence\n",
        "        word = sentence[i]\n",
        "\n",
        "        for j, current_tag in enumerate(tags):  # For a single tag:\n",
        "            max_prob = -float('inf')\n",
        "            best_prev_tag = 0\n",
        "            current_tag_index = tags_index[current_tag]\n",
        "\n",
        "            for k, prev_tag in enumerate(tags):  # For the tag of the word before this word\n",
        "                prev_tag_index = tags_index[prev_tag]\n",
        "\n",
        "                if word in vocab_index:\n",
        "                    prob = (delta[k, i-1] * transition_prob[prev_tag_index][current_tag_index] * emission_prob[current_tag_index][vocab_index[word]])\n",
        "                else:\n",
        "                    prob = (delta[k, i-1] * transition_prob[prev_tag_index][current_tag_index] * unknown_prob)\n",
        "\n",
        "\n",
        "                if prob > max_prob:\n",
        "                    max_prob = prob\n",
        "                    best_prev_tag = prev_tag_index\n",
        "\n",
        "            delta[j, i] = max_prob  # store the probability of tag j for word i\n",
        "            shi[j, i] = best_prev_tag\n",
        "            # print(f\"Word: {word}, Tag: {tags[j]}, Max Prob: {max_prob}\")\n",
        "\n",
        "\n",
        "# Trace back:\n",
        "    best_last_tag = np.argmax(delta[:, no_words-1])\n",
        "    best_path = [best_last_tag]\n",
        "\n",
        "    for i in range(no_words-1, 0, -1):\n",
        "        best_last_tag = (shi[best_last_tag, i])\n",
        "        best_path.insert(0, best_last_tag)\n",
        "\n",
        "    best_tag_sequence = [tags[i] for i in best_path]\n",
        "\n",
        "    return best_tag_sequence"
      ],
      "metadata": {
        "id": "FGgtp33daSxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TESTING"
      ],
      "metadata": {
        "id": "mO7AQ6GBGOA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def algo_accuracy(test_data, start_probs,transition_prob, emission_prob, tags = tags, B=True):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for sentence in test_data:\n",
        "      words = [word for word, _ in sentence]  # Extract words\n",
        "      true_tags = [tag for _, tag in sentence]  # Extract true tags\n",
        "\n",
        "\n",
        "      predicted_tags = viterbi(words, tags, start_probs, transition_prob, emission_prob)\n",
        "\n",
        "      correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
        "      total += len(true_tags)\n",
        "\n",
        "  accuracy = correct / total\n",
        "  if B:\n",
        "    print(f\"Viterbi Algorithm Accuracy: {accuracy:.2%}\")\n",
        "  else:\n",
        "    print(f\"Viterbi with Noise Handling Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "PEHCWJihGPUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(alpha, test_data = test_data, noisy_test_data = noisy_test_data, train_data=train_data):\n",
        "\n",
        "  start, tag_transition, emissions = form_count_tables(train_data, alpha)\n",
        "  start_probs, transition_prob, emission_prob = form_prob_table(start, tag_transition, emissions)\n",
        "\n",
        "  algo_accuracy(test_data, start_probs,transition_prob, emission_prob)\n",
        "  algo_accuracy( noisy_test_data, start_probs,transition_prob, emission_prob)\n"
      ],
      "metadata": {
        "id": "x11TZWt11C8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"WITHOUT SMOOTHING\")\n",
        "test(alpha = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTg9EaoGJl3Q",
        "outputId": "51377a03-bcc0-4723-d3a9-3e956fa76801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WITHOUT SMOOTHING\n",
            "Viterbi Algorithm Accuracy: 89.64%\n",
            "Viterbi Algorithm Accuracy: 81.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"With k=0.5 smoothing\")\n",
        "test(0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0tCdoQDGJY2",
        "outputId": "8d18e042-b447-47bc-f09c-140f15610968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With k=0.5 smoothing\n",
            "Viterbi Algorithm Accuracy: 85.82%\n",
            "Viterbi Algorithm Accuracy: 77.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"With k=1 Smoothing\")\n",
        "test(alpha = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-gm-eiM4B_4",
        "outputId": "b9b9f53a-9b28-4468-cdaa-95e58a0a0eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With k=1 Smoothing\n",
            "Viterbi Algorithm Accuracy: 83.45%\n",
            "Viterbi with Noise Handling Accuracy: 75.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"With k=0.3 Smoothing\")\n",
        "test(alpha = 0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5EV23laKBl5",
        "outputId": "342195b8-a5e9-4d63-faf9-b3d7d560c8bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With k=0.3 Smoothing\n",
            "Viterbi Algorithm Accuracy: 87.31%\n",
            "Viterbi with Noise Handling Accuracy: 79.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m6o6FmGXKDRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}